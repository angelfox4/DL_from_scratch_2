# Ch_02 Natural Language and Distributional Representation of Words

생성일: Jan 25, 2021 6:11 PM
태그: 상현 김

**[2장 자연어와 단어의 분산 표현]**

자연어 처리는 자연어를 처리하는 분야로 우리의 말을 컴퓨터가 이해시키기 위한 기술입니다. 컴퓨터에게 '단어의 의미'를 이해시키는 기법으로는 '시소러스 활용한 기법','통계 기반 기법', '추론 기반 기법(word2vec)'등이 있습니다.

시소러스는 사람이 직접 단어의 의미를 정의하는 방식입니다. 시소러스는 '시대 변화에 대응하기 어렵다.' , '사람을 쓰는 비용이 크다.' , '단어의 미묘한 차이를 표현할 수 없다.' 등의 문제점이 있습니다.

통계 기반 기법은 동시발생 행렬을 통해 벡터 간 유사도를 측정하여 유사단어를 파악합니다. 이때 동시발생 행렬을 PPMI 행렬로 변환하고 차원 축소를 통해 밀집벡터로 변환합니다. PTM 데이터셋에 통계 기반 기법을 적용해봤습니다.

**[정리]**

- WordNet 등의 시소러스를 이용하면 유의어를 얻거나 단어 사이의 유사도를 측정하는 등 유용한 작업을 할 수 있다.
- 시소러스 기반 기법은 시소러스를 작성하는 데 엄청난 인적 자원이 든다거나 새로운 단어에 대응하기 어렵다는 문제가 있다.
- 현재는 말뭉치를 이용해 단어를 벡터화하는 방식이 주로 쓰인다.
- 최근의 단어 벡터화 기법들은 대부분 '단어의 의미는 주변 단어에 의해 형성된다.'는 분포 가설에 기초한다.
- 통계 기반 기법은 말뭉치 안의 각 단어에 대해서 그 단어의 주변 단어의 빈도를 집계한다.(동시발생 행렬)
- 동시발생 행렬을 PPMI 행렬로 변환하고 다시 차원을 감소시킴으로써, 거대한 '희소벡터'를 작은 '밀집벡터'로 변환할 수 있다.
- 단어의 벡터 공간에서는 의미가 가까운 단어는 그 거리도 가까울 것으로 기대된다.

**[파일 설명]**

create_co_matrix: 동시발생 행렬 만드는 코드입니다.

similarity: 벡터 간 유사도(코사인 유사도)를 구하는 코드입니다.

most_similarity: 검색어와 비슷한 단어를 유사도 순으로 출력하는 함수 코드입니다.

dimensionality_reduction: svd를 통한 차원 축소를 구현한 코드입니다.

count_method_big: PTB 데이터셋에 통계 기반 기법을 적용한 코드입니다.

**[심화]**

차원축소

Singular Value Decomposition

![image](https://user-images.githubusercontent.com/68596881/105756434-f6c50080-5f8f-11eb-9b57-1be884942172.png)

V가 orthogonal matrix이므로 V의 역행렬(inverse)은 V의 전치행렬(transpose)

따라서, 다음을 만족한다.
![image](https://user-images.githubusercontent.com/68596881/105756467-03495900-5f90-11eb-86c1-0e40c3962308.png)

![image](https://user-images.githubusercontent.com/68596881/105756547-1ceaa080-5f90-11eb-91a8-2911461adcb0.png)

$obs_i$: i번째 데이터

$v_i$: i번째 열벡터(축을 나타낸다), i가 작을수록 대응되는 특이값이 크다

$t_i$ 는 XV의 열벡터로 X의 n개의 데이터와 V의 i번째 열벡터와의 내적을 통한 값으로 i번째 열(i번째 축)을 기준으로 데이터를 표현한 것이다. 여기서 내적을 사용했다는 것은 해당 축으로 정사영을 시킨 것을 알 수 있다. 

따라서 m개의 축 중에서 k개 (단, k≤m) 선택하여 내적을 하게 되면 k개 축으로 이루어진 공간으로 X를 축소시킬 수 있다. 단, k=m인 경우 축소가 아닌 공간의 변형만 이루어진다.

$\Sigma$는 대각행렬로 scale을 조절하므로 차원 축소된 XV의 코사인 유사도는 U를 통해서 구할 수 있다.

V의 열벡터들이 데이터의 분포를 고려하는 축인 이유

![image](https://user-images.githubusercontent.com/68596881/105756610-2a078f80-5f90-11eb-8fdf-606b2e466801.png)

특이값이 크기순으로 대각행렬을 이룰 경우 u와 v를 정규화된 벡터이므로 내적값은 -1과 1사이의 값을 갖는다.  그러므로 A의 각 성분의 크기는 각 특이값에 의해 정해진다. 따라서, A의 값들의 분포를 생각할 때, 큰 특이값에 대응되는 벡터(축)이 데이터의 분포에 큰 영향을 주는 축인 것을 알 수 있다.
